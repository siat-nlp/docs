{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"NLP and Deep Learning Tricks \u00b6 This repository aims to keep track of some practical and theoretical tricks in natural language processing (NLP) / deep learning / machine learning, etc. Most of these tricks are summarized by members of our group, while some others are borrowed from open-source sites. Data prepossessing \u00b6 Network architecture \u00b6 Seq2Seq \u00b6 Some tricks to train RNN and seq2seq models: Embedding size: 1024 or 512. Lower dimensionality like 256 can also lead to good performances. Higher does not necessarily lead to better performances. For the decoder: LSTM > GRU > Vanilla-RNN 2-4 layers seems generally enough. Deeper models with residual connections seems more difficult to converge (high variance). More tricks needs to be discovered. ResD (dense residual connections) > Res (only connected to previous layer) > no residual connections For encoder: Bidirectional > Unidirectional (reversed input) > Unidirectional Attention (additive) > Attention (multiplicative) > No attention. Authors suggest that attention act more as a skip connection mechanism than as a memory for the decoder. Ref Massive Exploration of Neural Machine Translation Architectures , Denny Britz, Anna Goldie et al. For seq2seq, reverse the order of the input sequence (['I', 'am', 'hungry'] becomes ['hungry', 'am', 'I']). Keep the target sequence intact. Why From the authors: \" This way, [...] that makes it easy for SGD to \u201cestablish communication\u201d between the input and the output. We found this simple data transformation to greatly improve the performance of the LSTM. \" Ref Sequence to Sequence Learning with Neural Networks , Ilya Sutskever et al. Char-RNN \u00b6 By training in an unsupervised way a network to predict the next character of a text (char-RNN), the network will learn a representation which can then be used for a supervised task (here sentiment analysis). Ref Learning to Generate Reviews and Discovering Sentiment , Ilya Sutskever et al. Parameters \u00b6 Learning rate \u00b6 The learning rate can be usually initialized as 0.0001, 0.0003, 0.001, 0.003, 0.01, 0.03, 0.1(3x growing up). A strategy used to select the hyperparameters is to randomly sample them (uniformly or logscale) and see the testing error after a few epoch. Beam size \u00b6 Usually set from 2 to 10. The larger beam size, the higher computational cost. Regularization \u00b6 Dropout \u00b6 To make Dropout works with RNN, it should only be applied on non-recurrent connections (between layers among a same timestep) [1]. Some more recent paper propose some tricks to make dropout works for recurrent connections[2]. Ref [1]. Recurrent Neural Network Regularization , Wojciech Zaremba et al. [2]. Recurrent Dropout without Memory Loss , Stanislau Semeniuta et al. Batch normalization \u00b6 adding a new normalization layer. Some additional tricks for accelerating BN Networks: * Increase the learning rate * Remove/reduce Dropout: speeds up training, without increasing overfitting * Remove/Reduce the L2 weight regularization * Accelerate the learning rate decay: because the network trains faster * Remove Local Response Normalization * Shuffle training examples more thoroughly: prevents the same examples from always appearing in a mini-batch together. (The authors speak about 1% improvements in the validation) * Reduce the photometric distortions Why Some good explanation at Quora . Reinforcement learning \u00b6 Asynchronous \u00b6 Train simultaneously multiple agents with different exploration policies (e.g., E-greedy with different values of epsilon) improve the robustness. Ref Asynchronous Methods for Deep Reinforcement Learning , V. Mnih. Skip frame \u00b6 Compute the action every 4 frames instead of every frames. For the other frames, repeat the action. Why Works well on Atari games, when the player reactivity doesn't need to be frame perfect. Using this trick allows to greatly speed up the training (About x4). Ref Playing Atari with Deep Reinforcement Learning , V. Mnih. History \u00b6 Instead of only taking the current frame as input, stack the last frames together on a single input (size (h, w, c) with 1 grayscale frame by channel). Combined with a skip frame (repeat action) of 4, that means we would stack the frames t, t-4, t-8 and t-12. Why This allows the network to have some momentum information. Ref Deep Reinforcement Learning with Double Q-learning , V. Mnih. Experience Replay \u00b6 Instead of updating every frames as the agent plays, to avoid correlations between the frames, it's better to sample a batch in the history of the transition taken (state, actionTaken, reward, nextState). This is basically the same idea as shuffling the dataset before training for supervised tasks. Some strategies exist to sample batches which contain more information (in the sense predicted reward different from real reward). Ref Prioritized Experience Replay , Tom Schaul et al. PAAC (Parallel Advantage Actor Critic) \u00b6 It's possible to simplify the the A3C algorithm by batching the agent experiences and using a single model with synchronous updates. Ref Efficient Parallel Methods for Deep Reinforcement Learning , Alfredo V. Clemente et al.","title":"NLP and DL Tricks"},{"location":"#nlp-and-deep-learning-tricks","text":"This repository aims to keep track of some practical and theoretical tricks in natural language processing (NLP) / deep learning / machine learning, etc. Most of these tricks are summarized by members of our group, while some others are borrowed from open-source sites.","title":"NLP and Deep Learning Tricks"},{"location":"#data-prepossessing","text":"","title":"Data prepossessing"},{"location":"#network-architecture","text":"","title":"Network architecture"},{"location":"#seq2seq","text":"Some tricks to train RNN and seq2seq models: Embedding size: 1024 or 512. Lower dimensionality like 256 can also lead to good performances. Higher does not necessarily lead to better performances. For the decoder: LSTM > GRU > Vanilla-RNN 2-4 layers seems generally enough. Deeper models with residual connections seems more difficult to converge (high variance). More tricks needs to be discovered. ResD (dense residual connections) > Res (only connected to previous layer) > no residual connections For encoder: Bidirectional > Unidirectional (reversed input) > Unidirectional Attention (additive) > Attention (multiplicative) > No attention. Authors suggest that attention act more as a skip connection mechanism than as a memory for the decoder. Ref Massive Exploration of Neural Machine Translation Architectures , Denny Britz, Anna Goldie et al. For seq2seq, reverse the order of the input sequence (['I', 'am', 'hungry'] becomes ['hungry', 'am', 'I']). Keep the target sequence intact. Why From the authors: \" This way, [...] that makes it easy for SGD to \u201cestablish communication\u201d between the input and the output. We found this simple data transformation to greatly improve the performance of the LSTM. \" Ref Sequence to Sequence Learning with Neural Networks , Ilya Sutskever et al.","title":"Seq2Seq"},{"location":"#char-rnn","text":"By training in an unsupervised way a network to predict the next character of a text (char-RNN), the network will learn a representation which can then be used for a supervised task (here sentiment analysis). Ref Learning to Generate Reviews and Discovering Sentiment , Ilya Sutskever et al.","title":"Char-RNN"},{"location":"#parameters","text":"","title":"Parameters"},{"location":"#learning-rate","text":"The learning rate can be usually initialized as 0.0001, 0.0003, 0.001, 0.003, 0.01, 0.03, 0.1(3x growing up). A strategy used to select the hyperparameters is to randomly sample them (uniformly or logscale) and see the testing error after a few epoch.","title":"Learning rate"},{"location":"#beam-size","text":"Usually set from 2 to 10. The larger beam size, the higher computational cost.","title":"Beam size"},{"location":"#regularization","text":"","title":"Regularization"},{"location":"#dropout","text":"To make Dropout works with RNN, it should only be applied on non-recurrent connections (between layers among a same timestep) [1]. Some more recent paper propose some tricks to make dropout works for recurrent connections[2]. Ref [1]. Recurrent Neural Network Regularization , Wojciech Zaremba et al. [2]. Recurrent Dropout without Memory Loss , Stanislau Semeniuta et al.","title":"Dropout"},{"location":"#batch-normalization","text":"adding a new normalization layer. Some additional tricks for accelerating BN Networks: * Increase the learning rate * Remove/reduce Dropout: speeds up training, without increasing overfitting * Remove/Reduce the L2 weight regularization * Accelerate the learning rate decay: because the network trains faster * Remove Local Response Normalization * Shuffle training examples more thoroughly: prevents the same examples from always appearing in a mini-batch together. (The authors speak about 1% improvements in the validation) * Reduce the photometric distortions Why Some good explanation at Quora .","title":"Batch normalization"},{"location":"#reinforcement-learning","text":"","title":"Reinforcement learning"},{"location":"#asynchronous","text":"Train simultaneously multiple agents with different exploration policies (e.g., E-greedy with different values of epsilon) improve the robustness. Ref Asynchronous Methods for Deep Reinforcement Learning , V. Mnih.","title":"Asynchronous"},{"location":"#skip-frame","text":"Compute the action every 4 frames instead of every frames. For the other frames, repeat the action. Why Works well on Atari games, when the player reactivity doesn't need to be frame perfect. Using this trick allows to greatly speed up the training (About x4). Ref Playing Atari with Deep Reinforcement Learning , V. Mnih.","title":"Skip frame"},{"location":"#history","text":"Instead of only taking the current frame as input, stack the last frames together on a single input (size (h, w, c) with 1 grayscale frame by channel). Combined with a skip frame (repeat action) of 4, that means we would stack the frames t, t-4, t-8 and t-12. Why This allows the network to have some momentum information. Ref Deep Reinforcement Learning with Double Q-learning , V. Mnih.","title":"History"},{"location":"#experience-replay","text":"Instead of updating every frames as the agent plays, to avoid correlations between the frames, it's better to sample a batch in the history of the transition taken (state, actionTaken, reward, nextState). This is basically the same idea as shuffling the dataset before training for supervised tasks. Some strategies exist to sample batches which contain more information (in the sense predicted reward different from real reward). Ref Prioritized Experience Replay , Tom Schaul et al.","title":"Experience Replay"},{"location":"#paac-parallel-advantage-actor-critic","text":"It's possible to simplify the the A3C algorithm by batching the agent experiences and using a single model with synchronous updates. Ref Efficient Parallel Methods for Deep Reinforcement Learning , Alfredo V. Clemente et al.","title":"PAAC (Parallel Advantage Actor Critic)"},{"location":"dl_framework/","text":"Deep Learning Framework Programming \u00b6 Programming in Tensorflow \u00b6 tf.variable_scope / tf.name_scope \u00b6 Both scopes have the same effect on all operations as well as variables, but name scope is ignored by tf . get_variable . Suggest use tf . variable_scope in most cases. Ref The difference between name scope and variable scope in tensorflow at stackoverflow . Model Save / Restore \u00b6 Usually, we create a helper saver = tf.train.Saver() to save and restore the whole model. However, if we want to use pre-trained model for fine-tuning or transfer learning, there are 2 ways: (1) Create the network by writing code to create each and every layer manually as the original model, and then use tf.train.Saver() to restore pre-trained model's checkpoint file. (2) Use .meta file and create the helper as saver = tf.train.import_meta_graph('xxx_model-xxx.meta') and then restore the pre-trained model. Ref More details are in this tutorial . Programming in PyTorch \u00b6 CUDA out of memory \u00b6 When RuntimeError: CUDA out of memory occurs, usually (1) check if exists too large tensors in computation graph; (2) downsize the batch size; (3) or use multiple GPUs to train. Note to split batch size when using nn.DataParallel . Ref Some other details are in this debug log . Online Tensorflow Serving \u00b6 TensorFlow Serving is a flexible, high-performance serving system for machine learning models, designed for production environments. Servables are the central abstraction in TensorFlow Serving. Servables are the underlying objects that clients use to perform computation (for example, a lookup or inference). The size and granularity of a Servable is flexible. A single Servable might include anything from a single shard of a lookup table to a single model to a tuple of inference models. Servables can be of any type and interface, enabling flexibility and future improvements such as: streaming results, experimental APIs, asynchronous modes of operation. How to deploy \u00b6 Tensorflow Serving follows the server-client architecture. While training a specific model, save it in the mode that can be used by tensorflow-serving. Deploy your model on a running docker to provide service. For clients, request server for prediction results of given data instances. The following is an example of the deployment procedure. Save a trained model The common way to save model in tensorflow looks like, 1 2 saver.save(session, checkpoint_prefix, global_step=current_step) tf.train.write_graph(sess.graph.as_graph_def(), checkpoint_prefix, \"graph\"+str(nn)+\".pb\", as_text=False) For tensorflow serving, we save like, 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ### define input&output signature signature = tf.saved_model.signature_def_utils.build_signature_def( inputs={ 'input_x1': tf.saved_model.utils.build_tensor_info(self.input_x1), 'input_x2': tf.saved_model.utils.build_tensor_info(self.input_x2), 'ent_x1': tf.saved_model.utils.build_tensor_info(self.ent_x1), 'ent_x2': tf.saved_model.utils.build_tensor_info(self.ent_x2), 'input_y': tf.saved_model.utils.build_tensor_info(self.input_y), 'add_fea': tf.saved_model.utils.build_tensor_info(self.add_fea), 'dropout_keep_prob': tf.saved_model.utils.build_tensor_info(self.dropout_keep_prob) }, outputs={ 'output': tf.saved_model.utils.build_tensor_info(self.soft_prob) }, method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME ) ### saving builder = tf.saved_model.builder.SavedModelBuilder(graph_save_dir) builder.add_meta_graph_and_variables(sess, [tf.saved_model.tag_constants.SERVING], {tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: signature}) builder.save() Define your own inputs and outputs according to the task. Run a serving docker and deploy your model 1 2 3 4 5 6 # pull a tensorflow-serving image $ sudo docker pull tensorflow/serving:latest-devel # run the serving docker $ sudo docker run -it -p 8500:8500 tensorflow/serving:latest-devel # copy your model file to the running docker (change the docker ID and your model path) $ sudo docker cp /data/huangweiyi/qaModel/code/kaaqa/runs/model 6d7d70e27ecc:/online_qa_model Note You need to create different version of your model for tensorflow-serving (refer to https://stackoverflow.com/questions/45544928/tensorflow-serving-no-versions-of-servable-model-found-under-base-path ) Deploy your model in the running docker \u00b6 1 $ tensorflow_model_server --port=8500 --model_name=qa --model_base_path=/online_qa_model Request the server for prediction results 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 hostport = '172.17.0.2:8500' channel = grpc.insecure_channel(hostport) stub = prediction_service_pb2_grpc.PredictionServiceStub(channel) request = predict_pb2.PredictRequest() request.model_spec.name = 'qa' inpH = InputHelper() x1_test, x2_test, ent_x1_test, ent_x2_test, y_test, x1_temp, x2_temp, add_fea_test = inpH.getTestSample(question, candidates) batches = inpH.batch_iter(list(zip(x1_test, x2_test, ent_x1_test, ent_x2_test, y_test, add_fea_test)), 10000, 1, shuffle=False) for db in batches: x1_dev_b, x2_dev_b, ent_x1_dev_b, ent_x2_dev_b, y_dev_b, add_fea_dev_b = zip(*db) for idx in range(len(x1_dev_b)): feature_dict = { \"input_x1\": x1_dev_b, \"input_x2\": x2_dev_b, \"ent_x1\": ent_x1_dev_b, \"ent_x2\": ent_x2_dev_b, \"input_y\": y_dev_b, \"add_fea\": add_fea_dev_b, \"dropout_keep_prob\": 1, } for key in ['input_x1', 'input_x2', 'ent_x1', 'ent_x2']: value = feature_dict.get(key)[idx].astype(np.int32) request.inputs[key].CopyFrom(tf.contrib.util.make_tensor_proto(value, shape=[1, value.size])) request.inputs['dropout_keep_prob'].CopyFrom(tf.contrib.util.make_tensor_proto(1.0, shape=[1])) request.inputs['input_y'].CopyFrom(tf.contrib.util.make_tensor_proto(1, shape=[1], dtype=np.int64)) value = add_fea_dev_b[0].astype(np.float32) request.inputs['add_fea'].CopyFrom(tf.contrib.util.make_tensor_proto(value, shape=[1, value.size])) result_future = stub.Predict.future(request, 3.0) score = np.array(result_future.result().outputs['output'].float_val)[1] Modify \"feature_dict\" according to your input variables. The variable \"score\" is the model output for your request instance. For more details, please refer to http://210.75.252.89:3000/hweiyi/aiLawAssistant/src/branch/master/ranking/client.py for all the codes. Ref A detailed illustration of saving model for tensorflow-serving ( https://zhuanlan.zhihu.com/p/40226973 ) Ref Documents of tensorflow-serving ( https://bookdown.org/leovan/TensorFlow-Learning-Notes/4-5-deploy-tensorflow-serving.html#using-tensorflow-serving-via-docker--docker--tensorflow-serving ) Ref An officail example ( https://github.com/tensorflow/serving/tree/master/tensorflow_serving/example )","title":"DL Framework Programming"},{"location":"dl_framework/#deep-learning-framework-programming","text":"","title":"Deep Learning Framework Programming"},{"location":"dl_framework/#programming-in-tensorflow","text":"","title":"Programming in Tensorflow"},{"location":"dl_framework/#tfvariable_scope-tfname_scope","text":"Both scopes have the same effect on all operations as well as variables, but name scope is ignored by tf . get_variable . Suggest use tf . variable_scope in most cases. Ref The difference between name scope and variable scope in tensorflow at stackoverflow .","title":"tf.variable_scope / tf.name_scope"},{"location":"dl_framework/#model-save-restore","text":"Usually, we create a helper saver = tf.train.Saver() to save and restore the whole model. However, if we want to use pre-trained model for fine-tuning or transfer learning, there are 2 ways: (1) Create the network by writing code to create each and every layer manually as the original model, and then use tf.train.Saver() to restore pre-trained model's checkpoint file. (2) Use .meta file and create the helper as saver = tf.train.import_meta_graph('xxx_model-xxx.meta') and then restore the pre-trained model. Ref More details are in this tutorial .","title":"Model Save / Restore"},{"location":"dl_framework/#programming-in-pytorch","text":"","title":"Programming in PyTorch"},{"location":"dl_framework/#cuda-out-of-memory","text":"When RuntimeError: CUDA out of memory occurs, usually (1) check if exists too large tensors in computation graph; (2) downsize the batch size; (3) or use multiple GPUs to train. Note to split batch size when using nn.DataParallel . Ref Some other details are in this debug log .","title":"CUDA out of memory"},{"location":"dl_framework/#online-tensorflow-serving","text":"TensorFlow Serving is a flexible, high-performance serving system for machine learning models, designed for production environments. Servables are the central abstraction in TensorFlow Serving. Servables are the underlying objects that clients use to perform computation (for example, a lookup or inference). The size and granularity of a Servable is flexible. A single Servable might include anything from a single shard of a lookup table to a single model to a tuple of inference models. Servables can be of any type and interface, enabling flexibility and future improvements such as: streaming results, experimental APIs, asynchronous modes of operation.","title":"Online Tensorflow Serving"},{"location":"dl_framework/#how-to-deploy","text":"Tensorflow Serving follows the server-client architecture. While training a specific model, save it in the mode that can be used by tensorflow-serving. Deploy your model on a running docker to provide service. For clients, request server for prediction results of given data instances. The following is an example of the deployment procedure. Save a trained model The common way to save model in tensorflow looks like, 1 2 saver.save(session, checkpoint_prefix, global_step=current_step) tf.train.write_graph(sess.graph.as_graph_def(), checkpoint_prefix, \"graph\"+str(nn)+\".pb\", as_text=False) For tensorflow serving, we save like, 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ### define input&output signature signature = tf.saved_model.signature_def_utils.build_signature_def( inputs={ 'input_x1': tf.saved_model.utils.build_tensor_info(self.input_x1), 'input_x2': tf.saved_model.utils.build_tensor_info(self.input_x2), 'ent_x1': tf.saved_model.utils.build_tensor_info(self.ent_x1), 'ent_x2': tf.saved_model.utils.build_tensor_info(self.ent_x2), 'input_y': tf.saved_model.utils.build_tensor_info(self.input_y), 'add_fea': tf.saved_model.utils.build_tensor_info(self.add_fea), 'dropout_keep_prob': tf.saved_model.utils.build_tensor_info(self.dropout_keep_prob) }, outputs={ 'output': tf.saved_model.utils.build_tensor_info(self.soft_prob) }, method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME ) ### saving builder = tf.saved_model.builder.SavedModelBuilder(graph_save_dir) builder.add_meta_graph_and_variables(sess, [tf.saved_model.tag_constants.SERVING], {tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: signature}) builder.save() Define your own inputs and outputs according to the task. Run a serving docker and deploy your model 1 2 3 4 5 6 # pull a tensorflow-serving image $ sudo docker pull tensorflow/serving:latest-devel # run the serving docker $ sudo docker run -it -p 8500:8500 tensorflow/serving:latest-devel # copy your model file to the running docker (change the docker ID and your model path) $ sudo docker cp /data/huangweiyi/qaModel/code/kaaqa/runs/model 6d7d70e27ecc:/online_qa_model Note You need to create different version of your model for tensorflow-serving (refer to https://stackoverflow.com/questions/45544928/tensorflow-serving-no-versions-of-servable-model-found-under-base-path )","title":"How to deploy"},{"location":"dl_framework/#deploy-your-model-in-the-running-docker","text":"1 $ tensorflow_model_server --port=8500 --model_name=qa --model_base_path=/online_qa_model Request the server for prediction results 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 hostport = '172.17.0.2:8500' channel = grpc.insecure_channel(hostport) stub = prediction_service_pb2_grpc.PredictionServiceStub(channel) request = predict_pb2.PredictRequest() request.model_spec.name = 'qa' inpH = InputHelper() x1_test, x2_test, ent_x1_test, ent_x2_test, y_test, x1_temp, x2_temp, add_fea_test = inpH.getTestSample(question, candidates) batches = inpH.batch_iter(list(zip(x1_test, x2_test, ent_x1_test, ent_x2_test, y_test, add_fea_test)), 10000, 1, shuffle=False) for db in batches: x1_dev_b, x2_dev_b, ent_x1_dev_b, ent_x2_dev_b, y_dev_b, add_fea_dev_b = zip(*db) for idx in range(len(x1_dev_b)): feature_dict = { \"input_x1\": x1_dev_b, \"input_x2\": x2_dev_b, \"ent_x1\": ent_x1_dev_b, \"ent_x2\": ent_x2_dev_b, \"input_y\": y_dev_b, \"add_fea\": add_fea_dev_b, \"dropout_keep_prob\": 1, } for key in ['input_x1', 'input_x2', 'ent_x1', 'ent_x2']: value = feature_dict.get(key)[idx].astype(np.int32) request.inputs[key].CopyFrom(tf.contrib.util.make_tensor_proto(value, shape=[1, value.size])) request.inputs['dropout_keep_prob'].CopyFrom(tf.contrib.util.make_tensor_proto(1.0, shape=[1])) request.inputs['input_y'].CopyFrom(tf.contrib.util.make_tensor_proto(1, shape=[1], dtype=np.int64)) value = add_fea_dev_b[0].astype(np.float32) request.inputs['add_fea'].CopyFrom(tf.contrib.util.make_tensor_proto(value, shape=[1, value.size])) result_future = stub.Predict.future(request, 3.0) score = np.array(result_future.result().outputs['output'].float_val)[1] Modify \"feature_dict\" according to your input variables. The variable \"score\" is the model output for your request instance. For more details, please refer to http://210.75.252.89:3000/hweiyi/aiLawAssistant/src/branch/master/ranking/client.py for all the codes. Ref A detailed illustration of saving model for tensorflow-serving ( https://zhuanlan.zhihu.com/p/40226973 ) Ref Documents of tensorflow-serving ( https://bookdown.org/leovan/TensorFlow-Learning-Notes/4-5-deploy-tensorflow-serving.html#using-tensorflow-serving-via-docker--docker--tensorflow-serving ) Ref An officail example ( https://github.com/tensorflow/serving/tree/master/tensorflow_serving/example )","title":"Deploy your model in the running docker"},{"location":"tutorial/","text":"Useful Tutorials \u00b6 under construction...","title":"Useful Tutorials"},{"location":"tutorial/#useful-tutorials","text":"under construction...","title":"Useful Tutorials"},{"location":"baselines/answer_selection/","text":"","title":"Answer Selection"},{"location":"baselines/aspect/","text":"","title":"Aspect Sentiment Analysis"},{"location":"baselines/captioning/","text":"","title":"Captioning"},{"location":"baselines/dialogue/","text":"","title":"Dialogue"},{"location":"baselines/question_answering/","text":"Question Answering \u00b6 Knowledge Base Question Answering \u00b6 Answer Selection \u00b6 Note: For Answer Selection, sequence length is an important parameter to be tuned. paper authors year TrecQA (TRAIN-ALL): MAP TrecQA (TRAIN-ALL): MRR TrecQA (clean): MAP TrecQA (clean): MRR TrecQA (TRAIN): MAP TrecQA (TRAIN): MRR WikiQA: MAP WikiQA: MRR InsuranceQA-test1: P@1 InsuranceQA-test2: P@1 SemEval-cQA: MAP SemEval-cQA: MRR code A Long Short-Term Memory Model for Answer Sentence Selection in Question Answering Di Wang and Eric Nyberg 2015 0.7134 0.7913 Learning to rank short text pairs with convolutional deep neural networks Aliaksei Severyn 2015 0.7459 0.8078 0.7329 0.7962 Wikiqa:Achallenge dataset for open-domain question answering Yi Yang 2015 0.652 0.6652 Abcnn: Attention-based convolutional neural network for modeling sentence pairs Wenpeng Yin, Hinrich Sch\u00a8 utze 2016 0.6921 0.7108 https://github.com/yinwenpeng/Answer_Selection aNMM : Ranking Short Answer Texts with Attention-Based Neural Matching Model Liu Yang1 Qingyao Ai1 Jiafeng Guo2 W. Bruce Croft 2016 0.7495 0.8109 0.7417 0.8102 Attentive pooling networks Cicero dos Santos 2016 0.753 0.8511 0.6886 0.6957 0.717 0.664 Convolutional Neural Networks vs . Convolution Kernels : Feature Engineering for Answer Sentence Reranking Kateryna Tymoshenko\u2020 and Daniele Bonadiman\u2020 and Alessandro Moschitti 2016 0.7518 0.8553 0.7417 0.7588 Employing External Rich Knowledge for Machine Comprehension BingningWang, Shangmin Guo, Kang Liu, Shizhu He, Jun Zhao 2016 0.6936 0.7094 Improved Representation Learning for Question Answer Matching Ming Tan, Cicero dos Santos, Bing Xiang & Bowen Zhou 2016 0.753 0.83 0.69 0.648 Inner attention based recurrent neural networks for answer selection BingningWang, Kang Liu, Jun Zhao 2016 0.7369 0.8208 0.7341 0.7418 0.7011 0.6514 LSTM-based Deep Learning Models for non-factoid answer selection Ming Tan, Cicero dos Santos, Bing Xiang & Bowen Zhou 2016 0.7279 0.824 0.681 0.633 Modeling relational information in question-answer pairs with convolutional neural networks Aliaksei Severyn 2016 0.7654 0.8186 0.7325 0.8018 0.6951 0.7107 Neural variational inference for text processing Yishu Miao 2016 0.6886 0.7069 Noise-contrastive estimation for answer selection with deep neural networks Jinfeng Rao1 , Hua He1 , and Jimmy Lin 2016 0.78 0.834 0.801 0.877 0.709 0.723 https://github.com/Jeffyrao/pairwise-neural-network Pairwise word interaction modeling with deep neural networks for semantic similarity measurement Hua He1 and Jimmy Lin 2016 0.7588 0.8219 0.709 0.7234 Sentence similarity learning by lexical decomposition and composition ZhiguoWang and Haitao Mi and Abraham Ittycheriah 2016 0.7058 0.7226 A compare aggregate model for matching text sequences ShuohangWang 2017 0.7433 0.7545 0.756 0.734 https://github.com/shuohangwang/SeqMatchSeq A compare aggregate model with dynamic-clip attention for answer selection Weijie Bian, Si Li, Zhao Yang, Guang Chen, Zhiqing Lin 2017 0.821 0.899 0.754 0.764 https://github.com/wjbianjason/Dynamic-Clip-Attention A Hybrid Framework for Text Modeling with Convolutional RNN ChenglongWang, Feijun Jiang, Hongxia Yang 2017 0.7427 0.7504 0.714 0.683 Bilateral multi-perspective matching for natural language sentences ZhiguoWang,Wael Hamza, Radu Florian 2017 0.802 0.875 0.718 0.731 https://github.com/zhiguowang/BiMPM Enhancing Recurrent Neural Networks with Positional Attention for Question Answering Qin Chen1, Qinmin Hu1, Jimmy Xiangji Huang2, Liang He1,3 andWeijie An 2017 0.7814 0.8513 0.7212 0.7312 Inter-weighted alignment network for sentence pair modeling Gehui Shen Yunlun Yang Zhi-Hong Deng 2017 0.822 0.889 0.733 0.75 Learning to Rank Question Answer Pairs with Holographic Dual LSTM Architecture Yi Tay1, Luu Anh Tuan2, and Siu Cheung Hui3 2017 0.7499 0.8153 0.752 0.8146 On the Benefit of Incorporating External Features in a Neural Architecture for Answer Sentence Selection Ruey-Cheng Chen, Evi Yulianti, Mark Sanderson,W. Bruce Cro\u017ft 2017 0.782 0.837 0.701 0.718 Ranking Kernels for Structures and Embeddings : A Hybrid Preference and Classification Model Kateryna Tymoshenko\u2020 and Daniele Bonadiman\u2020 and Alessandro Moschitti 2017 0.7219 0.7408 0.771 0.8345 https://github.com/iKernels/RelTextRank A Multi-View Fusion Neural Network for Answer Selection Lei Sha,\u2217 Xiaodong Zhang,\u2217 Feng Qian, Baobao Chang, Zhifang Sui 2018 0.7462 0.7576 0.8005 0.8718 CA-RNN : Using Context-Aligned Recurrent Neural Networks for Modeling Sentence Similarity Qin Chen,1 Qinmin Hu,1 Jimmy Xiangji Huang,2 Liang He 2018 0.8227 0.8886 0.7358 0.745 CAN : Enhancing Sentence Similarity Modeling with Collaborative and Adversarial Network Qin Chen1, Qinmin Hu, Jimmy Xiangji Huang3 and Liang He 2018 0.841 0.9168 0.7303 0.7431 Co-Stack Residual Affinity Networks with Multi-level Attention Refinement for Matching Text Sequences Yi Tay1, Luu Anh Tuan2, and Siu Cheung Hui3 2018 0.854 0.935 Context-Aware Answer Sentence Selection With Hierarchical Gated Recurrent Neural Networks Chuanqi Tan , FuruWei, Qingyu Zhou, Nan Yang, Bowen Du ,Weifeng Lv, and Ming Zhou 2018 0.7638 0.7825 Cross Temporal Recurrent Networks for Ranking Question Answer Pairs Yi Tay1, Luu Anh Tuan2, and Siu Cheung Hui3 2018 0.7712 0.8384 0.7582 0.8233 End-to-End Quantum-like Language Models with Application to Question Answering Peng Zhang1,\u2217, Jiabin Niu1, Zhan Su1, BenyouWang2, Liqun Ma3, Dawei Song 2018 0.7589 0.8254 0.6496 0.6594 Hermitian Co-Attention Networks for Text Matching in Asymmetrical Domains Yi Tay1, Anh Tuan Luu2, Siu Cheung Hui 2018 0.784 0.895 0.743 0.756 Hyperbolic representation learning for fast and efficient neural question answering Yi Tay1, Luu Anh Tuan2, and Siu Cheung Hui3 2018 0.77 0.825 0.784 0.865 0.712 0.727 0.795 null https://github.com/vanzytay/WSDM2018_HyperQA Knowledge as A Bridge: Improving Cross-domain Answer Selection with External Knowledge Yang Deng1, Ying Shen1,\u2217, Min Yang2, Yaliang Li3, Nan Du3,Wei Fan3, Kai Lei1 2018 0.797 0.85 Knowledge-aware Attentive Neural Network for Ranking Question Answer Pairs Ying Shen1, Yang Deng1, Min Yang2, Yaliang Li3, Nan Du3,Wei Fan3, Kai Lei 2018 0.7921 0.8444 0.8038 0.8846 0.7323 0.7494 Multihop Attention Networks for Question Answer Matching Nam Khanh Tran, Claudia Nieder\u00e9e 2018 0.813 0.893 0.722 0.738 0.705 0.669 https://github.com/namkhanhtran/nn4nqa Recurrently Controlled Recurrent Networks Yi Tay1, Luu Anh Tuan2, and Siu Cheung Hui3 2018 0.779 0.882 0.724 0.737 https://github.com/vanzytay/NIPS2018_RCRN Self-Training for Jointly Learning to Ask and Answer Questions Mrinmaya Sachan 2018 0.798 0.854 0.754 0.753 Semantic Linking in Convolutional Neural Networks for Answer Sentence Selection Massimo Nicosia\u2217 and Alessandro Moschitti\u2020 2018 0.7793 0.8489 0.7224 0.7391","title":"Question Answering"},{"location":"baselines/question_answering/#question-answering","text":"","title":"Question Answering"},{"location":"baselines/question_answering/#knowledge-base-question-answering","text":"","title":"Knowledge Base Question Answering"},{"location":"baselines/question_answering/#answer-selection","text":"Note: For Answer Selection, sequence length is an important parameter to be tuned. paper authors year TrecQA (TRAIN-ALL): MAP TrecQA (TRAIN-ALL): MRR TrecQA (clean): MAP TrecQA (clean): MRR TrecQA (TRAIN): MAP TrecQA (TRAIN): MRR WikiQA: MAP WikiQA: MRR InsuranceQA-test1: P@1 InsuranceQA-test2: P@1 SemEval-cQA: MAP SemEval-cQA: MRR code A Long Short-Term Memory Model for Answer Sentence Selection in Question Answering Di Wang and Eric Nyberg 2015 0.7134 0.7913 Learning to rank short text pairs with convolutional deep neural networks Aliaksei Severyn 2015 0.7459 0.8078 0.7329 0.7962 Wikiqa:Achallenge dataset for open-domain question answering Yi Yang 2015 0.652 0.6652 Abcnn: Attention-based convolutional neural network for modeling sentence pairs Wenpeng Yin, Hinrich Sch\u00a8 utze 2016 0.6921 0.7108 https://github.com/yinwenpeng/Answer_Selection aNMM : Ranking Short Answer Texts with Attention-Based Neural Matching Model Liu Yang1 Qingyao Ai1 Jiafeng Guo2 W. Bruce Croft 2016 0.7495 0.8109 0.7417 0.8102 Attentive pooling networks Cicero dos Santos 2016 0.753 0.8511 0.6886 0.6957 0.717 0.664 Convolutional Neural Networks vs . Convolution Kernels : Feature Engineering for Answer Sentence Reranking Kateryna Tymoshenko\u2020 and Daniele Bonadiman\u2020 and Alessandro Moschitti 2016 0.7518 0.8553 0.7417 0.7588 Employing External Rich Knowledge for Machine Comprehension BingningWang, Shangmin Guo, Kang Liu, Shizhu He, Jun Zhao 2016 0.6936 0.7094 Improved Representation Learning for Question Answer Matching Ming Tan, Cicero dos Santos, Bing Xiang & Bowen Zhou 2016 0.753 0.83 0.69 0.648 Inner attention based recurrent neural networks for answer selection BingningWang, Kang Liu, Jun Zhao 2016 0.7369 0.8208 0.7341 0.7418 0.7011 0.6514 LSTM-based Deep Learning Models for non-factoid answer selection Ming Tan, Cicero dos Santos, Bing Xiang & Bowen Zhou 2016 0.7279 0.824 0.681 0.633 Modeling relational information in question-answer pairs with convolutional neural networks Aliaksei Severyn 2016 0.7654 0.8186 0.7325 0.8018 0.6951 0.7107 Neural variational inference for text processing Yishu Miao 2016 0.6886 0.7069 Noise-contrastive estimation for answer selection with deep neural networks Jinfeng Rao1 , Hua He1 , and Jimmy Lin 2016 0.78 0.834 0.801 0.877 0.709 0.723 https://github.com/Jeffyrao/pairwise-neural-network Pairwise word interaction modeling with deep neural networks for semantic similarity measurement Hua He1 and Jimmy Lin 2016 0.7588 0.8219 0.709 0.7234 Sentence similarity learning by lexical decomposition and composition ZhiguoWang and Haitao Mi and Abraham Ittycheriah 2016 0.7058 0.7226 A compare aggregate model for matching text sequences ShuohangWang 2017 0.7433 0.7545 0.756 0.734 https://github.com/shuohangwang/SeqMatchSeq A compare aggregate model with dynamic-clip attention for answer selection Weijie Bian, Si Li, Zhao Yang, Guang Chen, Zhiqing Lin 2017 0.821 0.899 0.754 0.764 https://github.com/wjbianjason/Dynamic-Clip-Attention A Hybrid Framework for Text Modeling with Convolutional RNN ChenglongWang, Feijun Jiang, Hongxia Yang 2017 0.7427 0.7504 0.714 0.683 Bilateral multi-perspective matching for natural language sentences ZhiguoWang,Wael Hamza, Radu Florian 2017 0.802 0.875 0.718 0.731 https://github.com/zhiguowang/BiMPM Enhancing Recurrent Neural Networks with Positional Attention for Question Answering Qin Chen1, Qinmin Hu1, Jimmy Xiangji Huang2, Liang He1,3 andWeijie An 2017 0.7814 0.8513 0.7212 0.7312 Inter-weighted alignment network for sentence pair modeling Gehui Shen Yunlun Yang Zhi-Hong Deng 2017 0.822 0.889 0.733 0.75 Learning to Rank Question Answer Pairs with Holographic Dual LSTM Architecture Yi Tay1, Luu Anh Tuan2, and Siu Cheung Hui3 2017 0.7499 0.8153 0.752 0.8146 On the Benefit of Incorporating External Features in a Neural Architecture for Answer Sentence Selection Ruey-Cheng Chen, Evi Yulianti, Mark Sanderson,W. Bruce Cro\u017ft 2017 0.782 0.837 0.701 0.718 Ranking Kernels for Structures and Embeddings : A Hybrid Preference and Classification Model Kateryna Tymoshenko\u2020 and Daniele Bonadiman\u2020 and Alessandro Moschitti 2017 0.7219 0.7408 0.771 0.8345 https://github.com/iKernels/RelTextRank A Multi-View Fusion Neural Network for Answer Selection Lei Sha,\u2217 Xiaodong Zhang,\u2217 Feng Qian, Baobao Chang, Zhifang Sui 2018 0.7462 0.7576 0.8005 0.8718 CA-RNN : Using Context-Aligned Recurrent Neural Networks for Modeling Sentence Similarity Qin Chen,1 Qinmin Hu,1 Jimmy Xiangji Huang,2 Liang He 2018 0.8227 0.8886 0.7358 0.745 CAN : Enhancing Sentence Similarity Modeling with Collaborative and Adversarial Network Qin Chen1, Qinmin Hu, Jimmy Xiangji Huang3 and Liang He 2018 0.841 0.9168 0.7303 0.7431 Co-Stack Residual Affinity Networks with Multi-level Attention Refinement for Matching Text Sequences Yi Tay1, Luu Anh Tuan2, and Siu Cheung Hui3 2018 0.854 0.935 Context-Aware Answer Sentence Selection With Hierarchical Gated Recurrent Neural Networks Chuanqi Tan , FuruWei, Qingyu Zhou, Nan Yang, Bowen Du ,Weifeng Lv, and Ming Zhou 2018 0.7638 0.7825 Cross Temporal Recurrent Networks for Ranking Question Answer Pairs Yi Tay1, Luu Anh Tuan2, and Siu Cheung Hui3 2018 0.7712 0.8384 0.7582 0.8233 End-to-End Quantum-like Language Models with Application to Question Answering Peng Zhang1,\u2217, Jiabin Niu1, Zhan Su1, BenyouWang2, Liqun Ma3, Dawei Song 2018 0.7589 0.8254 0.6496 0.6594 Hermitian Co-Attention Networks for Text Matching in Asymmetrical Domains Yi Tay1, Anh Tuan Luu2, Siu Cheung Hui 2018 0.784 0.895 0.743 0.756 Hyperbolic representation learning for fast and efficient neural question answering Yi Tay1, Luu Anh Tuan2, and Siu Cheung Hui3 2018 0.77 0.825 0.784 0.865 0.712 0.727 0.795 null https://github.com/vanzytay/WSDM2018_HyperQA Knowledge as A Bridge: Improving Cross-domain Answer Selection with External Knowledge Yang Deng1, Ying Shen1,\u2217, Min Yang2, Yaliang Li3, Nan Du3,Wei Fan3, Kai Lei1 2018 0.797 0.85 Knowledge-aware Attentive Neural Network for Ranking Question Answer Pairs Ying Shen1, Yang Deng1, Min Yang2, Yaliang Li3, Nan Du3,Wei Fan3, Kai Lei 2018 0.7921 0.8444 0.8038 0.8846 0.7323 0.7494 Multihop Attention Networks for Question Answer Matching Nam Khanh Tran, Claudia Nieder\u00e9e 2018 0.813 0.893 0.722 0.738 0.705 0.669 https://github.com/namkhanhtran/nn4nqa Recurrently Controlled Recurrent Networks Yi Tay1, Luu Anh Tuan2, and Siu Cheung Hui3 2018 0.779 0.882 0.724 0.737 https://github.com/vanzytay/NIPS2018_RCRN Self-Training for Jointly Learning to Ask and Answer Questions Mrinmaya Sachan 2018 0.798 0.854 0.754 0.753 Semantic Linking in Convolutional Neural Networks for Answer Sentence Selection Massimo Nicosia\u2217 and Alessandro Moschitti\u2020 2018 0.7793 0.8489 0.7224 0.7391","title":"Answer Selection"},{"location":"baselines/summarization/","text":"","title":"Summarization"},{"location":"helper/","text":"\u5982\u4f55\u5206\u4eab\u4f60\u7684\u60f3\u6cd5\uff1f \u00b6 \u4f17\u4eba\u62fe\u67f4\u706b\u7130\u9ad8\uff0c\u4e3a\u4e86\u8ba9\u672c\u9879\u76ee\u7684\u5185\u5bb9\u80fd\u591f\u5e2e\u52a9\u5230\u66f4\u591a\u6709\u9700\u8981\u7684NLP\u7814\u7a76\u8005\u4e0e\u5f00\u53d1\u8005\uff0c\u6211\u4eec\u975e\u5e38\u6b22\u8fce\u6bcf\u4e00\u4e2a\u4eba\u90fd\u79ef\u6781\u5730\u8d21\u732e\u81ea\u5df1\u7684\u77e5\u8bc6\u4e0e\u529b\u91cf\uff0c\u8ba9\u8fd9\u4e2a\u9879\u76ee\u53d8\u5f97\u8d8a\u6765\u8d8a\u597d\u3002\u672c\u9879\u76ee\u63d0\u4f9b\u4e86\u7b80\u5355\u65b9\u4fbf\u7684\u77e5\u8bc6\u8d21\u732e\u65b9\u5f0f\uff0c\u4f60\u53ef\u4ee5\u6839\u636e\u4ee5\u4e0b\u4ecb\u7ecd\u7684\u5185\u5bb9\u4e0e\u6b65\u9aa4\u6765\u5206\u4eab\u4f60\u7684\u77e5\u8bc6 \uff01 \u5728\u5df2\u6709\u9875\u9762\u4e0a\u589e\u52a0\u6216\u4fee\u6539\u6587\u6863 \u00b6 \u9884\u5907\u6761\u4ef6 \u00b6 \u4e00\u4e2aGitHub\u8d26\u53f7\uff08\u82e5\u65e0\u53ef\u4ee5\u8bbf\u95ee GitHub \u8fdb\u884c\u8d26\u53f7\u7684\u6ce8\u518c\uff09 \u4e00\u4e2a\u53ef\u4ee5\u8fde\u63a5\u4e92\u8054\u7f51\u7684\u6d4f\u89c8\u5668 \u64cd\u4f5c\u6d41\u7a0b \u00b6 \u8bbf\u95ee\u7f51\u7ad9\u4e4b\u540e\uff0c\u8fdb\u5165\u5230\u60a8\u60f3\u8981\u8fdb\u884c\u66f4\u6539\u7684\u9875\u9762\uff0c\u53ef\u4ee5\u770b\u5230\u9875\u9762\u7684\u53f3\u4e0a\u65b9\u6709\u4e00\u4e2a\u94c5\u7b14\u5f62\u72b6\u7684\u6309\u94ae\uff08\u6bd4\u5982\u6211\u60f3\u66f4\u6539About\u9875\u9762\u4e0b\u7684Writing Tutorial\uff0c\u8fdb\u5165\u5230\u8be5\u9875\u9762\u540e\u53ef\u4ee5\u770b\u5230\u9875\u9762\u4e0a\u7684\u94c5\u7b14\u6309\u94ae\uff0c \u5982\u4e0b\u56fe\u7ea2\u8272\u65b9\u6846\u7684\u4f4d\u7f6e \uff09\u3002 \u70b9\u51fb\u8fd9\u4e2a\u94c5\u7b14\u6309\u94ae\uff0c\u53ef\u4ee5\u770b\u5230\u6211\u4eec\u8df3\u8f6c\u5230\u4e86\u8fd9\u4e2a\u9875\u9762\u7684md\u6587\u4ef6\uff08\u89c1\u4e0b\u56fe\uff09\u3002\u672c\u7f51\u7ad9\u4f7f\u7528\u4e86mkdocs\u8fdb\u884c\u6587\u6863\u7684\u751f\u6210\uff0c \u56e0\u6b64\u6211\u4eec\u53ea\u9700\u7f16\u8f91\u5bf9\u5e94\u9875\u9762\u7684md\u6587\u4ef6\u5373\u53ef\u4fee\u6539\u5bf9\u5e94\u6587\u6863\u4e2d\u7684\u5185\u5bb9 \u3002 \u6211\u4eec\u70b9\u51fb\u4e0a\u56fe\u4e2d\u7ea2\u6846\u4f4d\u7f6e\u5904\u7684\u94c5\u7b14\u6309\u94ae\uff0c\u82e5\u63d0\u793a\u4f60\u6ca1\u6709\u767b\u5f55\u65e0\u6cd5\u70b9\u51fb\u5219\u9700\u8981\u4f7f\u7528GitHub\u8d26\u53f7\u8fdb\u884c\u767b\u5f55\uff0c\u767b\u5f55\u540e\u5373\u53ef\u70b9\u51fb\u8be5\u94c5\u7b14\u72b6\u6309\u94ae\u3002\u6b64\u65f6\u5c06\u8fdb\u5165\u5230md\u6587\u4ef6\u4fee\u6539\u7684\u9875\u9762\uff08\u89c1\u4e0b\u56fe\uff09\u3002 \u8fdb\u884c\u6587\u4ef6\u7f16\u5199\u65f6\u4f60\u5fc5\u987b\u4f7f\u7528md\u6587\u4ef6\u652f\u6301\u7684markdown\u8bed\u6cd5 \uff0c\u6709\u5173markdown\u7684\u57fa\u672c\u8bed\u6cd5\u53ef\u4ee5\u53c2\u8003\u524d\u6587\u4e2d\u7684\u5df2\u7ecf\u5b58\u5728\u7684\u4ee3\u7801\uff0c\u76f8\u4fe1\u806a\u660e\u7684\u4f60\u601d\u8003\u7247\u523b\u5c31\u53ef\u4ee5\u8fdb\u884c\u6a21\u4eff\u7f16\u5199\u4e86\ud83e\udd23\uff0c\u5982\u679c\u4f60\u9700\u8981\u4e00\u4e9b\u53c2\u8003\u8d44\u6599\u53ef\u4ee5\u67e5\u770b Markdown \u8bed\u6cd5\u8bf4\u660e \u3002 \u6211\u4eec\u505a\u4e00\u4e9b\u7b80\u5355\u7684\u66f4\u6539\uff0c\u5728\u6587\u4ef6\u672b\u5c3e\u6dfb\u52a0\u4ee5\u4e0b\u4e00\u6bb5\u4ee3\u7801\uff1a 1 2 3 4 5 6 7 8 !!! bug Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. https://squidfunk.github.io/mkdocs-material/extensions/codehilite/#installation https://squidfunk.github.io/mkdocs-material/extensions/admonition/ \u5b83\u7684\u6548\u679c\u5982\u4e0b\uff1a Bug Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. https://squidfunk.github.io/mkdocs-material/extensions/codehilite/#installation https://squidfunk.github.io/mkdocs-material/extensions/admonition/ \u53ef\u4ee5\u770b\u5230\uff0c\u4f7f\u7528markdown\u8bed\u8a00\u53ef\u4ee5\u8f7b\u677e\u5730\u7f16\u5199\u51fa\u7f8e\u89c2\u7684\u6587\u6863\uff0c\u70b9\u51fb\u9875\u9762\u7684 Preview Changes \u53ef\u4ee5\u76f4\u63a5\u770b\u5230\u4fee\u6539\u7684\u7ed3\u679c\uff0c\u65b9\u4fbf\u6211\u4eec\u67e5\u770b\u662f\u5426\u5b58\u5728\u8bed\u6cd5\u9519\u8bef\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c \u672c\u6587\u6863\u8fd8\u652f\u6301markdown\u62d3\u5c55\u529f\u80fd\uff0c\u53ef\u4ee5\u4f7f\u7528\u8bf8\u5982\uff1a\u6570\u5b66\u516c\u5f0f\u3001\u8bed\u6cd5\u9ad8\u4eae\uff0c\u9ad8\u4eae\u6807\u6ce8\u7b49\u7b49\u539f\u751fmarkdown\u4e0d\u652f\u6301\u7684\u529f\u80fd \uff0c\u6709\u5173\u8fd9\u4e00\u90e8\u5206\u7684\u8be6\u7ec6\u5185\u5bb9\u8bf7\u53c2\u8003 Element \u3002 \u5f53\u6211\u4eec\u4fee\u6539\u5b8c\u6210\u540e\uff0c\u9700\u8981\u8fdb\u884c\u63d0\u4ea4\u4fee\u6539\u3002\u6eda\u52a8\u9875\u9762\u81f3\u5e95\u90e8\uff0c\u53ef\u4ee5\u770b\u5230 Propose file change \uff0c\u6839\u636e\u4f60\u7684\u4fee\u6539\u5185\u5bb9\u586b\u5199\u5bf9\u5e94\u7684\u63cf\u8ff0\uff0c\u5982\u4e0b\u56fe\u6240\u793a\u3002 \u968f\u540e\u70b9\u51fb\u63d0\u4ea4 Propose file change \uff0c\u6211\u4eec\u5c06\u4f1a\u8fdb\u5165\u5230\u6700\u7ec8\u7684\u63d0\u4ea4\u9875\u9762\u3002 \u5728\u9875\u9762\u4e0b\u65b9\u67e5\u770b\u6211\u4eec\u7684\u4fee\u6539\u65e0\u8bef\u540e\uff0c\u70b9\u51fb Create pull request \uff0c\u5c06\u4f1a\u628a\u6211\u4eec\u7684\u4fee\u6539\u5185\u5bb9\u6c47\u62a5\u81f3\u6587\u6863\u7f16\u8f91\u6240\u5728\u7684\u4ed3\u5e93\u4e2d\u3002\u7f16\u8f91\u90e8\u4f1a\u8fdb\u884c\u5185\u5bb9\u7684\u5ba1\u6838\uff0c\u4e00\u65e6\u5ba1\u6838\u901a\u8fc7\u4f60\u5f88\u5feb\u5c31\u4f1a\u5728\u7f51\u9875\u4e0a\u770b\u5230\u4f60\u7684\u8d21\u732e\u4e86\uff01\u4e3a\u4e86\u8ba9\u6211\u4eec\u7f16\u5199\u7684\u6587\u6863\u66f4\u52a0\u7edf\u4e00\uff0c \u6211\u4eec\u8fd8\u8bbe\u5b9a\u4e86\u4e00\u4e9b\u6587\u6863\u7684\u7f16\u5199\u8303\u5f0f\uff0c\u5e2e\u52a9\u6211\u4eec\u5199\u51fa\u66f4\u52a0\u7edf\u4e00\u7684\u6587\u6863\uff0c\u53ef\u4ee5\u8fdb\u5165 Writing Paradigm \u8fdb\u884c\u67e5\u770b \u3002 \u9879\u76ee\u662f\u5982\u4f55\u8fd0\u4f5c\u7684\uff1f \u00b6 \u76ee\u524d\u5185\u5bb9\u4ed3\u5e93\u5b89\u6392\u5728 NLP-DL-Tricks \u4e2d\uff0c\u5f53\u5176\u4ed6\u7528\u6237\u53d1\u8d77pull request\u65f6\uff0c\u5c06\u4f1a\u6709\u4ed3\u5e93\u62e5\u6709\u8005\u8fdb\u884c\u6574\u5408\u5230edit\u5206\u652f\u3002\u5f85\u51c6\u5907\u8fdb\u884c\u66f4\u65b0\u540e\uff0c\u4ed3\u5e93\u5f00\u53d1\u8005\u4f1a\u5bf9 edit\u4e0a\u7684\u4ee3\u7801\u6574\u5408\u5230master\u5206\u652f\u4e2d\uff0c\u518d\u8fdb\u884c\u7f51\u9875\u7684\u751f\u6210\u4e0e\u66f4\u65b0\u3002 \u6574\u4e2a\u6d41\u7a0b\u7684\u793a\u610f\u56fe\u5982\u4e0b\uff1a","title":"Writing Tutorial"},{"location":"helper/#_1","text":"\u4f17\u4eba\u62fe\u67f4\u706b\u7130\u9ad8\uff0c\u4e3a\u4e86\u8ba9\u672c\u9879\u76ee\u7684\u5185\u5bb9\u80fd\u591f\u5e2e\u52a9\u5230\u66f4\u591a\u6709\u9700\u8981\u7684NLP\u7814\u7a76\u8005\u4e0e\u5f00\u53d1\u8005\uff0c\u6211\u4eec\u975e\u5e38\u6b22\u8fce\u6bcf\u4e00\u4e2a\u4eba\u90fd\u79ef\u6781\u5730\u8d21\u732e\u81ea\u5df1\u7684\u77e5\u8bc6\u4e0e\u529b\u91cf\uff0c\u8ba9\u8fd9\u4e2a\u9879\u76ee\u53d8\u5f97\u8d8a\u6765\u8d8a\u597d\u3002\u672c\u9879\u76ee\u63d0\u4f9b\u4e86\u7b80\u5355\u65b9\u4fbf\u7684\u77e5\u8bc6\u8d21\u732e\u65b9\u5f0f\uff0c\u4f60\u53ef\u4ee5\u6839\u636e\u4ee5\u4e0b\u4ecb\u7ecd\u7684\u5185\u5bb9\u4e0e\u6b65\u9aa4\u6765\u5206\u4eab\u4f60\u7684\u77e5\u8bc6 \uff01","title":"\u5982\u4f55\u5206\u4eab\u4f60\u7684\u60f3\u6cd5\uff1f"},{"location":"helper/#_2","text":"","title":"\u5728\u5df2\u6709\u9875\u9762\u4e0a\u589e\u52a0\u6216\u4fee\u6539\u6587\u6863"},{"location":"helper/#_3","text":"\u4e00\u4e2aGitHub\u8d26\u53f7\uff08\u82e5\u65e0\u53ef\u4ee5\u8bbf\u95ee GitHub \u8fdb\u884c\u8d26\u53f7\u7684\u6ce8\u518c\uff09 \u4e00\u4e2a\u53ef\u4ee5\u8fde\u63a5\u4e92\u8054\u7f51\u7684\u6d4f\u89c8\u5668","title":"\u9884\u5907\u6761\u4ef6"},{"location":"helper/#_4","text":"\u8bbf\u95ee\u7f51\u7ad9\u4e4b\u540e\uff0c\u8fdb\u5165\u5230\u60a8\u60f3\u8981\u8fdb\u884c\u66f4\u6539\u7684\u9875\u9762\uff0c\u53ef\u4ee5\u770b\u5230\u9875\u9762\u7684\u53f3\u4e0a\u65b9\u6709\u4e00\u4e2a\u94c5\u7b14\u5f62\u72b6\u7684\u6309\u94ae\uff08\u6bd4\u5982\u6211\u60f3\u66f4\u6539About\u9875\u9762\u4e0b\u7684Writing Tutorial\uff0c\u8fdb\u5165\u5230\u8be5\u9875\u9762\u540e\u53ef\u4ee5\u770b\u5230\u9875\u9762\u4e0a\u7684\u94c5\u7b14\u6309\u94ae\uff0c \u5982\u4e0b\u56fe\u7ea2\u8272\u65b9\u6846\u7684\u4f4d\u7f6e \uff09\u3002 \u70b9\u51fb\u8fd9\u4e2a\u94c5\u7b14\u6309\u94ae\uff0c\u53ef\u4ee5\u770b\u5230\u6211\u4eec\u8df3\u8f6c\u5230\u4e86\u8fd9\u4e2a\u9875\u9762\u7684md\u6587\u4ef6\uff08\u89c1\u4e0b\u56fe\uff09\u3002\u672c\u7f51\u7ad9\u4f7f\u7528\u4e86mkdocs\u8fdb\u884c\u6587\u6863\u7684\u751f\u6210\uff0c \u56e0\u6b64\u6211\u4eec\u53ea\u9700\u7f16\u8f91\u5bf9\u5e94\u9875\u9762\u7684md\u6587\u4ef6\u5373\u53ef\u4fee\u6539\u5bf9\u5e94\u6587\u6863\u4e2d\u7684\u5185\u5bb9 \u3002 \u6211\u4eec\u70b9\u51fb\u4e0a\u56fe\u4e2d\u7ea2\u6846\u4f4d\u7f6e\u5904\u7684\u94c5\u7b14\u6309\u94ae\uff0c\u82e5\u63d0\u793a\u4f60\u6ca1\u6709\u767b\u5f55\u65e0\u6cd5\u70b9\u51fb\u5219\u9700\u8981\u4f7f\u7528GitHub\u8d26\u53f7\u8fdb\u884c\u767b\u5f55\uff0c\u767b\u5f55\u540e\u5373\u53ef\u70b9\u51fb\u8be5\u94c5\u7b14\u72b6\u6309\u94ae\u3002\u6b64\u65f6\u5c06\u8fdb\u5165\u5230md\u6587\u4ef6\u4fee\u6539\u7684\u9875\u9762\uff08\u89c1\u4e0b\u56fe\uff09\u3002 \u8fdb\u884c\u6587\u4ef6\u7f16\u5199\u65f6\u4f60\u5fc5\u987b\u4f7f\u7528md\u6587\u4ef6\u652f\u6301\u7684markdown\u8bed\u6cd5 \uff0c\u6709\u5173markdown\u7684\u57fa\u672c\u8bed\u6cd5\u53ef\u4ee5\u53c2\u8003\u524d\u6587\u4e2d\u7684\u5df2\u7ecf\u5b58\u5728\u7684\u4ee3\u7801\uff0c\u76f8\u4fe1\u806a\u660e\u7684\u4f60\u601d\u8003\u7247\u523b\u5c31\u53ef\u4ee5\u8fdb\u884c\u6a21\u4eff\u7f16\u5199\u4e86\ud83e\udd23\uff0c\u5982\u679c\u4f60\u9700\u8981\u4e00\u4e9b\u53c2\u8003\u8d44\u6599\u53ef\u4ee5\u67e5\u770b Markdown \u8bed\u6cd5\u8bf4\u660e \u3002 \u6211\u4eec\u505a\u4e00\u4e9b\u7b80\u5355\u7684\u66f4\u6539\uff0c\u5728\u6587\u4ef6\u672b\u5c3e\u6dfb\u52a0\u4ee5\u4e0b\u4e00\u6bb5\u4ee3\u7801\uff1a 1 2 3 4 5 6 7 8 !!! bug Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. https://squidfunk.github.io/mkdocs-material/extensions/codehilite/#installation https://squidfunk.github.io/mkdocs-material/extensions/admonition/ \u5b83\u7684\u6548\u679c\u5982\u4e0b\uff1a Bug Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. https://squidfunk.github.io/mkdocs-material/extensions/codehilite/#installation https://squidfunk.github.io/mkdocs-material/extensions/admonition/ \u53ef\u4ee5\u770b\u5230\uff0c\u4f7f\u7528markdown\u8bed\u8a00\u53ef\u4ee5\u8f7b\u677e\u5730\u7f16\u5199\u51fa\u7f8e\u89c2\u7684\u6587\u6863\uff0c\u70b9\u51fb\u9875\u9762\u7684 Preview Changes \u53ef\u4ee5\u76f4\u63a5\u770b\u5230\u4fee\u6539\u7684\u7ed3\u679c\uff0c\u65b9\u4fbf\u6211\u4eec\u67e5\u770b\u662f\u5426\u5b58\u5728\u8bed\u6cd5\u9519\u8bef\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c \u672c\u6587\u6863\u8fd8\u652f\u6301markdown\u62d3\u5c55\u529f\u80fd\uff0c\u53ef\u4ee5\u4f7f\u7528\u8bf8\u5982\uff1a\u6570\u5b66\u516c\u5f0f\u3001\u8bed\u6cd5\u9ad8\u4eae\uff0c\u9ad8\u4eae\u6807\u6ce8\u7b49\u7b49\u539f\u751fmarkdown\u4e0d\u652f\u6301\u7684\u529f\u80fd \uff0c\u6709\u5173\u8fd9\u4e00\u90e8\u5206\u7684\u8be6\u7ec6\u5185\u5bb9\u8bf7\u53c2\u8003 Element \u3002 \u5f53\u6211\u4eec\u4fee\u6539\u5b8c\u6210\u540e\uff0c\u9700\u8981\u8fdb\u884c\u63d0\u4ea4\u4fee\u6539\u3002\u6eda\u52a8\u9875\u9762\u81f3\u5e95\u90e8\uff0c\u53ef\u4ee5\u770b\u5230 Propose file change \uff0c\u6839\u636e\u4f60\u7684\u4fee\u6539\u5185\u5bb9\u586b\u5199\u5bf9\u5e94\u7684\u63cf\u8ff0\uff0c\u5982\u4e0b\u56fe\u6240\u793a\u3002 \u968f\u540e\u70b9\u51fb\u63d0\u4ea4 Propose file change \uff0c\u6211\u4eec\u5c06\u4f1a\u8fdb\u5165\u5230\u6700\u7ec8\u7684\u63d0\u4ea4\u9875\u9762\u3002 \u5728\u9875\u9762\u4e0b\u65b9\u67e5\u770b\u6211\u4eec\u7684\u4fee\u6539\u65e0\u8bef\u540e\uff0c\u70b9\u51fb Create pull request \uff0c\u5c06\u4f1a\u628a\u6211\u4eec\u7684\u4fee\u6539\u5185\u5bb9\u6c47\u62a5\u81f3\u6587\u6863\u7f16\u8f91\u6240\u5728\u7684\u4ed3\u5e93\u4e2d\u3002\u7f16\u8f91\u90e8\u4f1a\u8fdb\u884c\u5185\u5bb9\u7684\u5ba1\u6838\uff0c\u4e00\u65e6\u5ba1\u6838\u901a\u8fc7\u4f60\u5f88\u5feb\u5c31\u4f1a\u5728\u7f51\u9875\u4e0a\u770b\u5230\u4f60\u7684\u8d21\u732e\u4e86\uff01\u4e3a\u4e86\u8ba9\u6211\u4eec\u7f16\u5199\u7684\u6587\u6863\u66f4\u52a0\u7edf\u4e00\uff0c \u6211\u4eec\u8fd8\u8bbe\u5b9a\u4e86\u4e00\u4e9b\u6587\u6863\u7684\u7f16\u5199\u8303\u5f0f\uff0c\u5e2e\u52a9\u6211\u4eec\u5199\u51fa\u66f4\u52a0\u7edf\u4e00\u7684\u6587\u6863\uff0c\u53ef\u4ee5\u8fdb\u5165 Writing Paradigm \u8fdb\u884c\u67e5\u770b \u3002","title":"\u64cd\u4f5c\u6d41\u7a0b"},{"location":"helper/#_5","text":"\u76ee\u524d\u5185\u5bb9\u4ed3\u5e93\u5b89\u6392\u5728 NLP-DL-Tricks \u4e2d\uff0c\u5f53\u5176\u4ed6\u7528\u6237\u53d1\u8d77pull request\u65f6\uff0c\u5c06\u4f1a\u6709\u4ed3\u5e93\u62e5\u6709\u8005\u8fdb\u884c\u6574\u5408\u5230edit\u5206\u652f\u3002\u5f85\u51c6\u5907\u8fdb\u884c\u66f4\u65b0\u540e\uff0c\u4ed3\u5e93\u5f00\u53d1\u8005\u4f1a\u5bf9 edit\u4e0a\u7684\u4ee3\u7801\u6574\u5408\u5230master\u5206\u652f\u4e2d\uff0c\u518d\u8fdb\u884c\u7f51\u9875\u7684\u751f\u6210\u4e0e\u66f4\u65b0\u3002 \u6574\u4e2a\u6d41\u7a0b\u7684\u793a\u610f\u56fe\u5982\u4e0b\uff1a","title":"\u9879\u76ee\u662f\u5982\u4f55\u8fd0\u4f5c\u7684\uff1f"},{"location":"helper/element/","text":"\u53ef\u4ee5\u652f\u6301\u7684\u5143\u7d20 \u00b6 \u672c\u6587\u6863\u652f\u6301markdown\u62d3\u5c55\u529f\u80fd\uff0c\u53ef\u4ee5\u4f7f\u7528\u8bf8\u5982\uff1a\u6570\u5b66\u516c\u5f0f\u3001\u8bed\u6cd5\u9ad8\u4eae\uff0c\u9ad8\u4eae\u6807\u6ce8\u7b49\u7b49\u539f\u751fmarkdown\u4e0d\u652f\u6301\u7684\u529f\u80fd\u3002\u6709\u5173\u66f4\u591a\u62d3\u5c55\u529f\u80fd\u7684\u8be6\u7ec6\u63cf\u8ff0\u53ef\u4ee5\u53c2\u8003 \u6a21\u677f\u7f51\u7ad9 \uff0c\u5728\u8fd9\u91cc\u6211\u4eec\u53ea\u662f\u5217\u4e3e\u4e86\u4e00\u4e9b\u53ef\u80fd\u6bd4\u8f83\u5e38\u7528\u7684\u5143\u7d20\u4ee5\u4fbf\u53c2\u8003\u3002 \u4ee3\u7801 \u00b6 \u63d2\u5165\u4ee3\u7801 \u00b6 \u53ef\u4ee5\u65b9\u4fbf\u7684\u5728\u7f51\u9875\u4e2d\u63d2\u5165\u4ee3\u7801\uff0c\u5e76\u4e14\u53ef\u4ee5\u6307\u5b9a\u4e0d\u540c\u8bed\u8a00\u7684\u8bed\u6cd5\u9ad8\u4eae\uff0c\u5982\u4ee5\u4e0b\u4ee3\u7801\u53ef\u4ee5\u63d2\u5165Python\u8bed\u8a00\u7684\u4ee3\u7801\u5757\u3002 1 2 3 4 ``` python import numpy as np import torch.nn as nn ``` \u6548\u679c\uff1a 1 2 import numpy as np import torch.nn as nn \u4ee3\u7801\u7279\u5b9a\u884c\u9ad8\u4eae \u00b6 \u6709\u65f6\u5019\u4e3a\u4e86\u66f4\u52a0\u76f4\u89c2\u7684\u8fdb\u884c\u5c55\u793a\uff0c\u4f60\u53ef\u4ee5\u6307\u5b9a\u4ee3\u7801\u5757\u4e2d\u8fdb\u884c\u9ad8\u4eae\u7684\u884c\uff0c\u5982\u4e0b\u6240\u793a\u3002 1 2 3 4 5 6 7 8 ``` python hl_lines=\"3 4\" \"\"\" Bubble sort \"\"\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] ``` \u6548\u679c\uff1a 1 2 3 4 5 6 \"\"\" Bubble sort \"\"\" def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ] \u66f4\u591a\u6709\u5173\u4ee3\u7801\u7684\u4f7f\u7528\u7ec6\u8282\u53ef\u4ee5\u53c2\u8003 CodeHilite \u8868\u683c \u00b6 1 2 3 4 5 dog | bird | cat ----|------|---- foo | foo | foo bar | bar | bar baz | baz | baz \u6548\u679c\uff1a dog bird cat foo foo foo bar bar bar baz baz baz \u6570\u5b66\u516c\u5f0f \u00b6 \u6587\u6863\u652f\u6301\u4f7f\u7528Latex\u8fdb\u884c\u6570\u5b66\u516c\u5f0f\u7684\u7f16\u8f91\u3002 1 2 3 $$ \\frac{n!}{k!(n-k)!} = \\binom{n}{k} $$ \u6548\u679c\uff1a \\frac{n!}{k!(n-k)!} = \\binom{n}{k} \\frac{n!}{k!(n-k)!} = \\binom{n}{k} Admonition \u00b6 \u4e3a\u4e86\u66f4\u52a0\u7a81\u51fa\u7684\u5c55\u793a\u663e\u8457\u4fe1\u606f\uff0c\u4f60\u53ef\u4ee5\u4f7f\u7528Admonition\uff0c\u6211\u4eec\u89c4\u5b9a\u4e86\u4e24\u79cd\u6bd4\u8f83\u5e38\u7528\u7684\u5f62\u5f0f\uff1b\u5206\u522b\u662f\u201cWhy\u201d\uff1a\u7528\u6765\u63cf\u8ff0/\u89e3\u91ca\u5b9e\u9a8c/\u4ee3\u7801\u7684\u73b0\u8c61\u3001\u201cRef\u201d\uff1a\u7528\u6765\u4ecb\u7ecd\u4f60\u6240\u5f15\u7528\u7684\u53c2\u8003\u6587\u732e\u3002\u5b83\u4eec\u7684\u5b9e\u73b0\u65b9\u5f0f\u5982\u4e0b\u6240\u793a\u3002 1 2 !!! info \"Ref\" [Massive Exploration of Neural Machine Translation Architectures](https://arxiv.org/abs/1703.03906), Denny Britz, Anna Goldie et al. \u6548\u679c\uff1a Ref Massive Exploration of Neural Machine Translation Architectures , Denny Britz, Anna Goldie et al. 1 2 !!! question \"Why\" From the authors: \"*This way, [...] that makes it easy for SGD to \u201cestablish communication\u201d between the input and the output. We found this simple data transformation to greatly improve the performance of the LSTM.*\" \u6548\u679c\uff1a Why From the authors: \" This way, [...] that makes it easy for SGD to \u201cestablish communication\u201d between the input and the output. We found this simple data transformation to greatly improve the performance of the LSTM. \" \u66f4\u591a\u6709\u5173Admonition\u7684\u4f7f\u7528\u7ec6\u8282\u53ef\u4ee5\u53c2\u8003 Admonition","title":"Element"},{"location":"helper/element/#_1","text":"\u672c\u6587\u6863\u652f\u6301markdown\u62d3\u5c55\u529f\u80fd\uff0c\u53ef\u4ee5\u4f7f\u7528\u8bf8\u5982\uff1a\u6570\u5b66\u516c\u5f0f\u3001\u8bed\u6cd5\u9ad8\u4eae\uff0c\u9ad8\u4eae\u6807\u6ce8\u7b49\u7b49\u539f\u751fmarkdown\u4e0d\u652f\u6301\u7684\u529f\u80fd\u3002\u6709\u5173\u66f4\u591a\u62d3\u5c55\u529f\u80fd\u7684\u8be6\u7ec6\u63cf\u8ff0\u53ef\u4ee5\u53c2\u8003 \u6a21\u677f\u7f51\u7ad9 \uff0c\u5728\u8fd9\u91cc\u6211\u4eec\u53ea\u662f\u5217\u4e3e\u4e86\u4e00\u4e9b\u53ef\u80fd\u6bd4\u8f83\u5e38\u7528\u7684\u5143\u7d20\u4ee5\u4fbf\u53c2\u8003\u3002","title":"\u53ef\u4ee5\u652f\u6301\u7684\u5143\u7d20"},{"location":"helper/element/#_2","text":"","title":"\u4ee3\u7801"},{"location":"helper/element/#_3","text":"\u53ef\u4ee5\u65b9\u4fbf\u7684\u5728\u7f51\u9875\u4e2d\u63d2\u5165\u4ee3\u7801\uff0c\u5e76\u4e14\u53ef\u4ee5\u6307\u5b9a\u4e0d\u540c\u8bed\u8a00\u7684\u8bed\u6cd5\u9ad8\u4eae\uff0c\u5982\u4ee5\u4e0b\u4ee3\u7801\u53ef\u4ee5\u63d2\u5165Python\u8bed\u8a00\u7684\u4ee3\u7801\u5757\u3002 1 2 3 4 ``` python import numpy as np import torch.nn as nn ``` \u6548\u679c\uff1a 1 2 import numpy as np import torch.nn as nn","title":"\u63d2\u5165\u4ee3\u7801"},{"location":"helper/element/#_4","text":"\u6709\u65f6\u5019\u4e3a\u4e86\u66f4\u52a0\u76f4\u89c2\u7684\u8fdb\u884c\u5c55\u793a\uff0c\u4f60\u53ef\u4ee5\u6307\u5b9a\u4ee3\u7801\u5757\u4e2d\u8fdb\u884c\u9ad8\u4eae\u7684\u884c\uff0c\u5982\u4e0b\u6240\u793a\u3002 1 2 3 4 5 6 7 8 ``` python hl_lines=\"3 4\" \"\"\" Bubble sort \"\"\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] ``` \u6548\u679c\uff1a 1 2 3 4 5 6 \"\"\" Bubble sort \"\"\" def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ] \u66f4\u591a\u6709\u5173\u4ee3\u7801\u7684\u4f7f\u7528\u7ec6\u8282\u53ef\u4ee5\u53c2\u8003 CodeHilite","title":"\u4ee3\u7801\u7279\u5b9a\u884c\u9ad8\u4eae"},{"location":"helper/element/#_5","text":"1 2 3 4 5 dog | bird | cat ----|------|---- foo | foo | foo bar | bar | bar baz | baz | baz \u6548\u679c\uff1a dog bird cat foo foo foo bar bar bar baz baz baz","title":"\u8868\u683c"},{"location":"helper/element/#_6","text":"\u6587\u6863\u652f\u6301\u4f7f\u7528Latex\u8fdb\u884c\u6570\u5b66\u516c\u5f0f\u7684\u7f16\u8f91\u3002 1 2 3 $$ \\frac{n!}{k!(n-k)!} = \\binom{n}{k} $$ \u6548\u679c\uff1a \\frac{n!}{k!(n-k)!} = \\binom{n}{k} \\frac{n!}{k!(n-k)!} = \\binom{n}{k}","title":"\u6570\u5b66\u516c\u5f0f"},{"location":"helper/element/#admonition","text":"\u4e3a\u4e86\u66f4\u52a0\u7a81\u51fa\u7684\u5c55\u793a\u663e\u8457\u4fe1\u606f\uff0c\u4f60\u53ef\u4ee5\u4f7f\u7528Admonition\uff0c\u6211\u4eec\u89c4\u5b9a\u4e86\u4e24\u79cd\u6bd4\u8f83\u5e38\u7528\u7684\u5f62\u5f0f\uff1b\u5206\u522b\u662f\u201cWhy\u201d\uff1a\u7528\u6765\u63cf\u8ff0/\u89e3\u91ca\u5b9e\u9a8c/\u4ee3\u7801\u7684\u73b0\u8c61\u3001\u201cRef\u201d\uff1a\u7528\u6765\u4ecb\u7ecd\u4f60\u6240\u5f15\u7528\u7684\u53c2\u8003\u6587\u732e\u3002\u5b83\u4eec\u7684\u5b9e\u73b0\u65b9\u5f0f\u5982\u4e0b\u6240\u793a\u3002 1 2 !!! info \"Ref\" [Massive Exploration of Neural Machine Translation Architectures](https://arxiv.org/abs/1703.03906), Denny Britz, Anna Goldie et al. \u6548\u679c\uff1a Ref Massive Exploration of Neural Machine Translation Architectures , Denny Britz, Anna Goldie et al. 1 2 !!! question \"Why\" From the authors: \"*This way, [...] that makes it easy for SGD to \u201cestablish communication\u201d between the input and the output. We found this simple data transformation to greatly improve the performance of the LSTM.*\" \u6548\u679c\uff1a Why From the authors: \" This way, [...] that makes it easy for SGD to \u201cestablish communication\u201d between the input and the output. We found this simple data transformation to greatly improve the performance of the LSTM. \" \u66f4\u591a\u6709\u5173Admonition\u7684\u4f7f\u7528\u7ec6\u8282\u53ef\u4ee5\u53c2\u8003 Admonition","title":"Admonition"},{"location":"helper/writing_paradigm/","text":"\u6587\u6863\u7f16\u5199\u6a21\u677f \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 ## Network architecture ### Seq2Seq Some tricks to train RNN and seq2seq models: * Embedding size: 1024 or 512. Lower dimensionality like 256 can also lead to good performances. Higher does not necessarily lead to better performances. * For the decoder: LSTM > GRU > Vanilla-RNN * 2-4 layers seems generally enough. Deeper models with residual connections seems more difficult to converge (high variance). More tricks needs to be discovered. * ResD (dense residual connections) > Res (only connected to previous layer) > no residual connections * For encoder: Bidirectional > Unidirectional (reversed input) > Unidirectional * Attention (additive) > Attention (multiplicative) > No attention. Authors suggest that attention act more as a skip connection mechanism than as a memory for the decoder. !!! info \"Ref\" [Massive Exploration of Neural Machine Translation Architectures](https://arxiv.org/abs/1703.03906), Denny Britz, Anna Goldie et al. For seq2seq, reverse the order of the input sequence (\\['I', 'am', 'hungry'\\] becomes \\['hungry', 'am', 'I'\\]). Keep the target sequence intact. !!! question \"Why\" From the authors: \"*This way, [...] that makes it easy for SGD to \u201cestablish communication\u201d between the input and the output. We found this simple data transformation to greatly improve the performance of the LSTM.*\" !!! info \"Ref\" [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215), Ilya Sutskever et al. \u6548\u679c\uff1a Network architecture \u00b6 Seq2Seq \u00b6 Some tricks to train RNN and seq2seq models: Embedding size: 1024 or 512. Lower dimensionality like 256 can also lead to good performances. Higher does not necessarily lead to better performances. For the decoder: LSTM > GRU > Vanilla-RNN 2-4 layers seems generally enough. Deeper models with residual connections seems more difficult to converge (high variance). More tricks needs to be discovered. ResD (dense residual connections) > Res (only connected to previous layer) > no residual connections For encoder: Bidirectional > Unidirectional (reversed input) > Unidirectional Attention (additive) > Attention (multiplicative) > No attention. Authors suggest that attention act more as a skip connection mechanism than as a memory for the decoder. Ref Massive Exploration of Neural Machine Translation Architectures , Denny Britz, Anna Goldie et al. For seq2seq, reverse the order of the input sequence (['I', 'am', 'hungry'] becomes ['hungry', 'am', 'I']). Keep the target sequence intact. Why From the authors: \" This way, [...] that makes it easy for SGD to \u201cestablish communication\u201d between the input and the output. We found this simple data transformation to greatly improve the performance of the LSTM. \" Ref Sequence to Sequence Learning with Neural Networks , Ilya Sutskever et al.","title":"Writing Paradigm"},{"location":"helper/writing_paradigm/#_1","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 ## Network architecture ### Seq2Seq Some tricks to train RNN and seq2seq models: * Embedding size: 1024 or 512. Lower dimensionality like 256 can also lead to good performances. Higher does not necessarily lead to better performances. * For the decoder: LSTM > GRU > Vanilla-RNN * 2-4 layers seems generally enough. Deeper models with residual connections seems more difficult to converge (high variance). More tricks needs to be discovered. * ResD (dense residual connections) > Res (only connected to previous layer) > no residual connections * For encoder: Bidirectional > Unidirectional (reversed input) > Unidirectional * Attention (additive) > Attention (multiplicative) > No attention. Authors suggest that attention act more as a skip connection mechanism than as a memory for the decoder. !!! info \"Ref\" [Massive Exploration of Neural Machine Translation Architectures](https://arxiv.org/abs/1703.03906), Denny Britz, Anna Goldie et al. For seq2seq, reverse the order of the input sequence (\\['I', 'am', 'hungry'\\] becomes \\['hungry', 'am', 'I'\\]). Keep the target sequence intact. !!! question \"Why\" From the authors: \"*This way, [...] that makes it easy for SGD to \u201cestablish communication\u201d between the input and the output. We found this simple data transformation to greatly improve the performance of the LSTM.*\" !!! info \"Ref\" [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215), Ilya Sutskever et al. \u6548\u679c\uff1a","title":"\u6587\u6863\u7f16\u5199\u6a21\u677f"},{"location":"helper/writing_paradigm/#network-architecture","text":"","title":"Network architecture"},{"location":"helper/writing_paradigm/#seq2seq","text":"Some tricks to train RNN and seq2seq models: Embedding size: 1024 or 512. Lower dimensionality like 256 can also lead to good performances. Higher does not necessarily lead to better performances. For the decoder: LSTM > GRU > Vanilla-RNN 2-4 layers seems generally enough. Deeper models with residual connections seems more difficult to converge (high variance). More tricks needs to be discovered. ResD (dense residual connections) > Res (only connected to previous layer) > no residual connections For encoder: Bidirectional > Unidirectional (reversed input) > Unidirectional Attention (additive) > Attention (multiplicative) > No attention. Authors suggest that attention act more as a skip connection mechanism than as a memory for the decoder. Ref Massive Exploration of Neural Machine Translation Architectures , Denny Britz, Anna Goldie et al. For seq2seq, reverse the order of the input sequence (['I', 'am', 'hungry'] becomes ['hungry', 'am', 'I']). Keep the target sequence intact. Why From the authors: \" This way, [...] that makes it easy for SGD to \u201cestablish communication\u201d between the input and the output. We found this simple data transformation to greatly improve the performance of the LSTM. \" Ref Sequence to Sequence Learning with Neural Networks , Ilya Sutskever et al.","title":"Seq2Seq"}]}